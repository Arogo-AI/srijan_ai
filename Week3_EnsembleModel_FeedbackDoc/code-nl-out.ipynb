{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10722068,"sourceType":"datasetVersion","datasetId":6646532}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfinal_df = pd.read_csv('/kaggle/input/df-final/combined_cleaned_df_final.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:23.025859Z","iopub.execute_input":"2025-02-11T11:58:23.026124Z","iopub.status.idle":"2025-02-11T11:58:24.011771Z","shell.execute_reply.started":"2025-02-11T11:58:23.026092Z","shell.execute_reply":"2025-02-11T11:58:24.010969Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"final_df = final_df.drop('Unnamed: 0', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:24.015265Z","iopub.execute_input":"2025-02-11T11:58:24.015502Z","iopub.status.idle":"2025-02-11T11:58:24.031379Z","shell.execute_reply.started":"2025-02-11T11:58:24.015462Z","shell.execute_reply":"2025-02-11T11:58:24.030528Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ngender_encoder = LabelEncoder()\n\nfinal_df['gender'] = gender_encoder.fit_transform(final_df['gender'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:25.182848Z","iopub.execute_input":"2025-02-11T11:58:25.183117Z","iopub.status.idle":"2025-02-11T11:58:25.677743Z","shell.execute_reply.started":"2025-02-11T11:58:25.183097Z","shell.execute_reply":"2025-02-11T11:58:25.676878Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df_icd9 = final_df[final_df['icd_version'] == 9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:26.869397Z","iopub.execute_input":"2025-02-11T11:58:26.869854Z","iopub.status.idle":"2025-02-11T11:58:26.876215Z","shell.execute_reply.started":"2025-02-11T11:58:26.869828Z","shell.execute_reply":"2025-02-11T11:58:26.875572Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nicd_encoded = encoder.fit_transform(df_icd9[['icd_code']])\nicd_encoded_df = pd.DataFrame(\n    icd_encoded,\n    columns=encoder.get_feature_names_out(['icd_code'])\n)\n\nicd_encoded_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:28.455054Z","iopub.execute_input":"2025-02-11T11:58:28.455441Z","iopub.status.idle":"2025-02-11T11:58:28.541382Z","shell.execute_reply.started":"2025-02-11T11:58:28.455410Z","shell.execute_reply":"2025-02-11T11:58:28.540542Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      icd_code_00845  icd_code_0088  icd_code_0090  icd_code_01300  \\\n0                0.0            0.0            0.0             0.0   \n1                0.0            0.0            0.0             0.0   \n2                0.0            0.0            0.0             0.0   \n3                0.0            0.0            0.0             0.0   \n4                0.0            0.0            0.0             0.0   \n...              ...            ...            ...             ...   \n4570             0.0            0.0            0.0             0.0   \n4571             0.0            0.0            0.0             0.0   \n4572             0.0            0.0            0.0             0.0   \n4573             0.0            0.0            0.0             0.0   \n4574             0.0            0.0            0.0             0.0   \n\n      icd_code_01896  icd_code_0340  icd_code_035  icd_code_0380  \\\n0                0.0            0.0           0.0            0.0   \n1                0.0            0.0           0.0            0.0   \n2                0.0            0.0           0.0            0.0   \n3                0.0            0.0           0.0            0.0   \n4                0.0            0.0           0.0            0.0   \n...              ...            ...           ...            ...   \n4570             0.0            0.0           0.0            0.0   \n4571             0.0            0.0           0.0            0.0   \n4572             0.0            0.0           0.0            0.0   \n4573             0.0            0.0           0.0            0.0   \n4574             0.0            0.0           0.0            0.0   \n\n      icd_code_03811  icd_code_03812  ...  icd_code_V5811  icd_code_V5812  \\\n0                0.0             0.0  ...             0.0             0.0   \n1                0.0             0.0  ...             0.0             0.0   \n2                0.0             0.0  ...             0.0             0.0   \n3                0.0             0.0  ...             0.0             0.0   \n4                0.0             0.0  ...             0.0             0.0   \n...              ...             ...  ...             ...             ...   \n4570             0.0             0.0  ...             0.0             0.0   \n4571             0.0             0.0  ...             0.0             0.0   \n4572             0.0             0.0  ...             0.0             0.0   \n4573             0.0             0.0  ...             0.0             0.0   \n4574             0.0             0.0  ...             0.0             0.0   \n\n      icd_code_V5883  icd_code_V600  icd_code_V618  icd_code_V6284  \\\n0                0.0            0.0            0.0             0.0   \n1                0.0            0.0            0.0             0.0   \n2                0.0            0.0            0.0             0.0   \n3                0.0            0.0            0.0             0.0   \n4                0.0            0.0            0.0             0.0   \n...              ...            ...            ...             ...   \n4570             0.0            0.0            0.0             0.0   \n4571             0.0            0.0            0.0             0.0   \n4572             0.0            0.0            0.0             0.0   \n4573             0.0            0.0            0.0             0.0   \n4574             0.0            0.0            0.0             0.0   \n\n      icd_code_V714  icd_code_V7189  icd_code_V7281  icd_code_V7651  \n0               0.0             0.0             0.0             0.0  \n1               0.0             0.0             0.0             0.0  \n2               0.0             0.0             0.0             0.0  \n3               0.0             0.0             0.0             0.0  \n4               0.0             0.0             0.0             0.0  \n...             ...             ...             ...             ...  \n4570            0.0             0.0             0.0             0.0  \n4571            0.0             0.0             0.0             0.0  \n4572            0.0             0.0             0.0             0.0  \n4573            0.0             0.0             0.0             0.0  \n4574            0.0             0.0             0.0             0.0  \n\n[4575 rows x 1203 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>icd_code_00845</th>\n      <th>icd_code_0088</th>\n      <th>icd_code_0090</th>\n      <th>icd_code_01300</th>\n      <th>icd_code_01896</th>\n      <th>icd_code_0340</th>\n      <th>icd_code_035</th>\n      <th>icd_code_0380</th>\n      <th>icd_code_03811</th>\n      <th>icd_code_03812</th>\n      <th>...</th>\n      <th>icd_code_V5811</th>\n      <th>icd_code_V5812</th>\n      <th>icd_code_V5883</th>\n      <th>icd_code_V600</th>\n      <th>icd_code_V618</th>\n      <th>icd_code_V6284</th>\n      <th>icd_code_V714</th>\n      <th>icd_code_V7189</th>\n      <th>icd_code_V7281</th>\n      <th>icd_code_V7651</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4570</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4571</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4572</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4573</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4574</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4575 rows × 1203 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"y = icd_encoded_df\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:30.286360Z","iopub.execute_input":"2025-02-11T11:58:30.286693Z","iopub.status.idle":"2025-02-11T11:58:30.316033Z","shell.execute_reply.started":"2025-02-11T11:58:30.286665Z","shell.execute_reply":"2025-02-11T11:58:30.315314Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      icd_code_00845  icd_code_0088  icd_code_0090  icd_code_01300  \\\n0                0.0            0.0            0.0             0.0   \n1                0.0            0.0            0.0             0.0   \n2                0.0            0.0            0.0             0.0   \n3                0.0            0.0            0.0             0.0   \n4                0.0            0.0            0.0             0.0   \n...              ...            ...            ...             ...   \n4570             0.0            0.0            0.0             0.0   \n4571             0.0            0.0            0.0             0.0   \n4572             0.0            0.0            0.0             0.0   \n4573             0.0            0.0            0.0             0.0   \n4574             0.0            0.0            0.0             0.0   \n\n      icd_code_01896  icd_code_0340  icd_code_035  icd_code_0380  \\\n0                0.0            0.0           0.0            0.0   \n1                0.0            0.0           0.0            0.0   \n2                0.0            0.0           0.0            0.0   \n3                0.0            0.0           0.0            0.0   \n4                0.0            0.0           0.0            0.0   \n...              ...            ...           ...            ...   \n4570             0.0            0.0           0.0            0.0   \n4571             0.0            0.0           0.0            0.0   \n4572             0.0            0.0           0.0            0.0   \n4573             0.0            0.0           0.0            0.0   \n4574             0.0            0.0           0.0            0.0   \n\n      icd_code_03811  icd_code_03812  ...  icd_code_V5811  icd_code_V5812  \\\n0                0.0             0.0  ...             0.0             0.0   \n1                0.0             0.0  ...             0.0             0.0   \n2                0.0             0.0  ...             0.0             0.0   \n3                0.0             0.0  ...             0.0             0.0   \n4                0.0             0.0  ...             0.0             0.0   \n...              ...             ...  ...             ...             ...   \n4570             0.0             0.0  ...             0.0             0.0   \n4571             0.0             0.0  ...             0.0             0.0   \n4572             0.0             0.0  ...             0.0             0.0   \n4573             0.0             0.0  ...             0.0             0.0   \n4574             0.0             0.0  ...             0.0             0.0   \n\n      icd_code_V5883  icd_code_V600  icd_code_V618  icd_code_V6284  \\\n0                0.0            0.0            0.0             0.0   \n1                0.0            0.0            0.0             0.0   \n2                0.0            0.0            0.0             0.0   \n3                0.0            0.0            0.0             0.0   \n4                0.0            0.0            0.0             0.0   \n...              ...            ...            ...             ...   \n4570             0.0            0.0            0.0             0.0   \n4571             0.0            0.0            0.0             0.0   \n4572             0.0            0.0            0.0             0.0   \n4573             0.0            0.0            0.0             0.0   \n4574             0.0            0.0            0.0             0.0   \n\n      icd_code_V714  icd_code_V7189  icd_code_V7281  icd_code_V7651  \n0               0.0             0.0             0.0             0.0  \n1               0.0             0.0             0.0             0.0  \n2               0.0             0.0             0.0             0.0  \n3               0.0             0.0             0.0             0.0  \n4               0.0             0.0             0.0             0.0  \n...             ...             ...             ...             ...  \n4570            0.0             0.0             0.0             0.0  \n4571            0.0             0.0             0.0             0.0  \n4572            0.0             0.0             0.0             0.0  \n4573            0.0             0.0             0.0             0.0  \n4574            0.0             0.0             0.0             0.0  \n\n[4575 rows x 1203 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>icd_code_00845</th>\n      <th>icd_code_0088</th>\n      <th>icd_code_0090</th>\n      <th>icd_code_01300</th>\n      <th>icd_code_01896</th>\n      <th>icd_code_0340</th>\n      <th>icd_code_035</th>\n      <th>icd_code_0380</th>\n      <th>icd_code_03811</th>\n      <th>icd_code_03812</th>\n      <th>...</th>\n      <th>icd_code_V5811</th>\n      <th>icd_code_V5812</th>\n      <th>icd_code_V5883</th>\n      <th>icd_code_V600</th>\n      <th>icd_code_V618</th>\n      <th>icd_code_V6284</th>\n      <th>icd_code_V714</th>\n      <th>icd_code_V7189</th>\n      <th>icd_code_V7281</th>\n      <th>icd_code_V7651</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4570</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4571</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4572</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4573</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4574</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4575 rows × 1203 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"X = df_icd9.drop(['hadm_id', 'icd_code', 'subject_id'], axis=1)\nX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:32.352988Z","iopub.execute_input":"2025-02-11T11:58:32.353334Z","iopub.status.idle":"2025-02-11T11:58:32.382115Z","shell.execute_reply.started":"2025-02-11T11:58:32.353295Z","shell.execute_reply":"2025-02-11T11:58:32.381493Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      gender  icd_version  50868  50882     50893  50902  50912  50931  \\\n0          0          9.0    9.0   28.0  7.800000  105.0    0.3   99.0   \n1          0          9.0   14.0   25.0  7.800000   92.0    0.3   71.0   \n2          0          9.0   11.0   26.0  8.600000   95.0    0.6   95.0   \n3          0          9.0   14.0   21.0  9.300000  102.0    0.5  115.0   \n8          1          9.0   14.0   28.0  8.746584  101.0    0.8   93.0   \n...      ...          ...    ...    ...       ...    ...    ...    ...   \n7266       1          9.0   12.0   27.0  8.800000  104.0    1.2  142.0   \n7267       1          9.0   17.0   24.0  9.000000  105.0    2.1  163.0   \n7268       1          9.0   15.0   25.0  8.700000  104.0    1.2  104.0   \n7269       1          9.0   17.0   22.0  8.600000  106.0    1.1  140.0   \n7270       1          9.0   18.0   23.0  8.600000  101.0    1.2   88.0   \n\n         50960    50970  ...  51237  51248  51249  51250  51265  51274  \\\n0     1.700000  3.60000  ...    1.5   33.4   33.8   99.0   71.0   16.6   \n1     1.900000  3.30000  ...    1.5   34.5   35.0   99.0  137.0   16.3   \n2     2.400000  3.90000  ...    1.5   35.9   34.8  103.0  133.0   15.8   \n3     2.300000  2.40000  ...    1.8   34.9   34.1  102.0   94.0   19.5   \n8     1.944314  3.54061  ...    1.0   29.6   35.6   83.0  286.0   10.8   \n...        ...      ...  ...    ...    ...    ...    ...    ...    ...   \n7266  2.100000  2.80000  ...    3.3   29.6   32.3   92.0  185.0   34.9   \n7267  2.300000  4.40000  ...    2.3   29.9   32.9   91.0  183.0   24.9   \n7268  2.000000  3.50000  ...    1.0   29.1   34.5   85.0  258.0   10.8   \n7269  1.900000  2.90000  ...    1.1   29.8   32.4   92.0  228.0   11.6   \n7270  2.000000  3.20000  ...    1.2   29.1   33.3   88.0  551.0   13.4   \n\n          51275  51277  51279  51301  \n0     32.300000   15.3   3.80    4.2  \n1     36.346258   15.7   3.60    6.6  \n2     32.500000   16.0   3.36    7.5  \n3     34.200000   15.8   3.40    4.1  \n8     35.200000   14.7   3.58    6.6  \n...         ...    ...    ...    ...  \n7266  57.100000   14.8   3.65    3.5  \n7267  41.300000   18.0   3.37    4.6  \n7268  70.800000   13.5   4.27    6.4  \n7269  33.200000   15.5   2.82    5.2  \n7270  65.400000   13.5   3.32    7.3  \n\n[4575 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>icd_version</th>\n      <th>50868</th>\n      <th>50882</th>\n      <th>50893</th>\n      <th>50902</th>\n      <th>50912</th>\n      <th>50931</th>\n      <th>50960</th>\n      <th>50970</th>\n      <th>...</th>\n      <th>51237</th>\n      <th>51248</th>\n      <th>51249</th>\n      <th>51250</th>\n      <th>51265</th>\n      <th>51274</th>\n      <th>51275</th>\n      <th>51277</th>\n      <th>51279</th>\n      <th>51301</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>28.0</td>\n      <td>7.800000</td>\n      <td>105.0</td>\n      <td>0.3</td>\n      <td>99.0</td>\n      <td>1.700000</td>\n      <td>3.60000</td>\n      <td>...</td>\n      <td>1.5</td>\n      <td>33.4</td>\n      <td>33.8</td>\n      <td>99.0</td>\n      <td>71.0</td>\n      <td>16.6</td>\n      <td>32.300000</td>\n      <td>15.3</td>\n      <td>3.80</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>25.0</td>\n      <td>7.800000</td>\n      <td>92.0</td>\n      <td>0.3</td>\n      <td>71.0</td>\n      <td>1.900000</td>\n      <td>3.30000</td>\n      <td>...</td>\n      <td>1.5</td>\n      <td>34.5</td>\n      <td>35.0</td>\n      <td>99.0</td>\n      <td>137.0</td>\n      <td>16.3</td>\n      <td>36.346258</td>\n      <td>15.7</td>\n      <td>3.60</td>\n      <td>6.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>9.0</td>\n      <td>11.0</td>\n      <td>26.0</td>\n      <td>8.600000</td>\n      <td>95.0</td>\n      <td>0.6</td>\n      <td>95.0</td>\n      <td>2.400000</td>\n      <td>3.90000</td>\n      <td>...</td>\n      <td>1.5</td>\n      <td>35.9</td>\n      <td>34.8</td>\n      <td>103.0</td>\n      <td>133.0</td>\n      <td>15.8</td>\n      <td>32.500000</td>\n      <td>16.0</td>\n      <td>3.36</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>21.0</td>\n      <td>9.300000</td>\n      <td>102.0</td>\n      <td>0.5</td>\n      <td>115.0</td>\n      <td>2.300000</td>\n      <td>2.40000</td>\n      <td>...</td>\n      <td>1.8</td>\n      <td>34.9</td>\n      <td>34.1</td>\n      <td>102.0</td>\n      <td>94.0</td>\n      <td>19.5</td>\n      <td>34.200000</td>\n      <td>15.8</td>\n      <td>3.40</td>\n      <td>4.1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>28.0</td>\n      <td>8.746584</td>\n      <td>101.0</td>\n      <td>0.8</td>\n      <td>93.0</td>\n      <td>1.944314</td>\n      <td>3.54061</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>29.6</td>\n      <td>35.6</td>\n      <td>83.0</td>\n      <td>286.0</td>\n      <td>10.8</td>\n      <td>35.200000</td>\n      <td>14.7</td>\n      <td>3.58</td>\n      <td>6.6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7266</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>12.0</td>\n      <td>27.0</td>\n      <td>8.800000</td>\n      <td>104.0</td>\n      <td>1.2</td>\n      <td>142.0</td>\n      <td>2.100000</td>\n      <td>2.80000</td>\n      <td>...</td>\n      <td>3.3</td>\n      <td>29.6</td>\n      <td>32.3</td>\n      <td>92.0</td>\n      <td>185.0</td>\n      <td>34.9</td>\n      <td>57.100000</td>\n      <td>14.8</td>\n      <td>3.65</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>7267</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>17.0</td>\n      <td>24.0</td>\n      <td>9.000000</td>\n      <td>105.0</td>\n      <td>2.1</td>\n      <td>163.0</td>\n      <td>2.300000</td>\n      <td>4.40000</td>\n      <td>...</td>\n      <td>2.3</td>\n      <td>29.9</td>\n      <td>32.9</td>\n      <td>91.0</td>\n      <td>183.0</td>\n      <td>24.9</td>\n      <td>41.300000</td>\n      <td>18.0</td>\n      <td>3.37</td>\n      <td>4.6</td>\n    </tr>\n    <tr>\n      <th>7268</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>15.0</td>\n      <td>25.0</td>\n      <td>8.700000</td>\n      <td>104.0</td>\n      <td>1.2</td>\n      <td>104.0</td>\n      <td>2.000000</td>\n      <td>3.50000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>29.1</td>\n      <td>34.5</td>\n      <td>85.0</td>\n      <td>258.0</td>\n      <td>10.8</td>\n      <td>70.800000</td>\n      <td>13.5</td>\n      <td>4.27</td>\n      <td>6.4</td>\n    </tr>\n    <tr>\n      <th>7269</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>17.0</td>\n      <td>22.0</td>\n      <td>8.600000</td>\n      <td>106.0</td>\n      <td>1.1</td>\n      <td>140.0</td>\n      <td>1.900000</td>\n      <td>2.90000</td>\n      <td>...</td>\n      <td>1.1</td>\n      <td>29.8</td>\n      <td>32.4</td>\n      <td>92.0</td>\n      <td>228.0</td>\n      <td>11.6</td>\n      <td>33.200000</td>\n      <td>15.5</td>\n      <td>2.82</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>1</td>\n      <td>9.0</td>\n      <td>18.0</td>\n      <td>23.0</td>\n      <td>8.600000</td>\n      <td>101.0</td>\n      <td>1.2</td>\n      <td>88.0</td>\n      <td>2.000000</td>\n      <td>3.20000</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>29.1</td>\n      <td>33.3</td>\n      <td>88.0</td>\n      <td>551.0</td>\n      <td>13.4</td>\n      <td>65.400000</td>\n      <td>13.5</td>\n      <td>3.32</td>\n      <td>7.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>4575 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"y_labels = y.idxmax(axis=1)\nX.columns = X.columns.astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:33.876976Z","iopub.execute_input":"2025-02-11T11:58:33.877266Z","iopub.status.idle":"2025-02-11T11:58:33.905500Z","shell.execute_reply.started":"2025-02-11T11:58:33.877242Z","shell.execute_reply":"2025-02-11T11:58:33.904891Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler() \nX_scaled = scaler.fit_transform(X)\n\nX_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:35.470705Z","iopub.execute_input":"2025-02-11T11:58:35.470979Z","iopub.status.idle":"2025-02-11T11:58:35.494506Z","shell.execute_reply.started":"2025-02-11T11:58:35.470957Z","shell.execute_reply":"2025-02-11T11:58:35.493825Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([[-0.99281271,  0.        , -1.5842577 , ...,  0.31320025,\n        -0.10101255, -0.61857567],\n       [-0.99281271,  0.        ,  0.04039634, ...,  0.51295987,\n        -0.39831272, -0.31963363],\n       [-0.99281271,  0.        , -0.93439608, ...,  0.66277958,\n        -0.75507293, -0.20753037],\n       ...,\n       [ 1.00723932,  0.        ,  0.36532715, ..., -0.58571802,\n         0.59764286, -0.34454547],\n       [ 1.00723932,  0.        ,  1.01518877, ...,  0.41308006,\n        -1.5577834 , -0.49401649],\n       [ 1.00723932,  0.        ,  1.34011958, ..., -0.58571802,\n        -0.81453296, -0.23244221]])"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\ny_class = np.argmax(y.values, axis=1)\ny_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:58:36.570229Z","iopub.execute_input":"2025-02-11T11:58:36.570547Z","iopub.status.idle":"2025-02-11T11:58:36.577551Z","shell.execute_reply.started":"2025-02-11T11:58:36.570522Z","shell.execute_reply":"2025-02-11T11:58:36.576884Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([ 634,   28,   26, ...,  363, 1167,  414])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(\n    objective='multi:softmax', \n    num_class=len(y.columns),  \n    eval_metric='mlogloss',    \n    n_estimators=150,\n    random_state=42\n)\n\nmodel_xgb.fit(X_scaled, y_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:10:34.911932Z","iopub.execute_input":"2025-02-11T12:10:34.912257Z","iopub.status.idle":"2025-02-11T12:11:34.713887Z","shell.execute_reply.started":"2025-02-11T12:10:34.912232Z","shell.execute_reply":"2025-02-11T12:11:34.713036Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=150,\n              n_jobs=None, num_class=1203, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=150,\n              n_jobs=None, num_class=1203, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=150,\n              n_jobs=None, num_class=1203, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"y_pred = model_xgb.predict(X_scaled)\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_class, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:13:23.142981Z","iopub.execute_input":"2025-02-11T12:13:23.143278Z","iopub.status.idle":"2025-02-11T12:13:25.764517Z","shell.execute_reply.started":"2025-02-11T12:13:23.143255Z","shell.execute_reply":"2025-02-11T12:13:25.763586Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.91\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import joblib\n\n# Save the model using joblib\njoblib.dump(model_xgb, \"xgb_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:15:23.078086Z","iopub.execute_input":"2025-02-11T12:15:23.078380Z","iopub.status.idle":"2025-02-11T12:15:25.278434Z","shell.execute_reply.started":"2025-02-11T12:15:23.078346Z","shell.execute_reply":"2025-02-11T12:15:25.277426Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"['xgb_model.pkl']"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import f1_score\n\nlgb_params = {\n    'objective': 'multiclass',\n    'num_class': len(y.columns),\n    'metric': 'multi_logloss',\n    'boosting_type': 'gbdt',\n    'device': 'gpu',\n    'num_leaves': 60,\n    'learning_rate': 0.001,\n    'feature_fraction': 0.9,\n    'verbose': -1\n}\n\ntrain_data = lgb.Dataset(X_scaled, label=y_class)\n\nlgb_model = lgb.train(\n    lgb_params,\n    train_data,\n    num_boost_round=200,\n    valid_sets=[train_data],\n    callbacks=[lgb.log_evaluation(50)]\n)\n\ny_pred_lgb = lgb_model.predict(X_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:16:24.577539Z","iopub.execute_input":"2025-02-11T12:16:24.577853Z","iopub.status.idle":"2025-02-11T12:43:55.855202Z","shell.execute_reply.started":"2025-02-11T12:16:24.577831Z","shell.execute_reply":"2025-02-11T12:43:55.853950Z"}},"outputs":[{"name":"stdout","text":"[50]\ttraining's multi_logloss: 4.34342\n[100]\ttraining's multi_logloss: 3.44072\n[150]\ttraining's multi_logloss: 2.87256\n[200]\ttraining's multi_logloss: 2.46909\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"y_pred_lgb_class = np.argmax(y_pred_lgb, axis=1)\nprint(\"LightGBM F1-Score:\", f1_score(y_class, y_pred_lgb_class, average='weighted'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:45:10.653106Z","iopub.execute_input":"2025-02-11T12:45:10.653442Z","iopub.status.idle":"2025-02-11T12:45:10.668286Z","shell.execute_reply.started":"2025-02-11T12:45:10.653414Z","shell.execute_reply":"2025-02-11T12:45:10.667684Z"}},"outputs":[{"name":"stdout","text":"LightGBM F1-Score: 0.9446399679491807\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_class, y_pred_lgb_class)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:45:16.068955Z","iopub.execute_input":"2025-02-11T12:45:16.069223Z","iopub.status.idle":"2025-02-11T12:45:16.074841Z","shell.execute_reply.started":"2025-02-11T12:45:16.069201Z","shell.execute_reply":"2025-02-11T12:45:16.073973Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.94\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Save the model to disk\nlgb_model.save_model('lgb_model.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:45:55.988014Z","iopub.execute_input":"2025-02-11T12:45:55.988329Z","iopub.status.idle":"2025-02-11T12:46:14.340112Z","shell.execute_reply.started":"2025-02-11T12:45:55.988303Z","shell.execute_reply":"2025-02-11T12:46:14.339396Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<lightgbm.basic.Booster at 0x7d3156c9aef0>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ------------------------------------------------------------------------------\n# 1. Convert your data into PyTorch tensors\n# ------------------------------------------------------------------------------\n# Assume X and y are NumPy arrays:\n#   X has shape (4575, 25)\n#   y has shape (4575, 1203), where each row is one-hot.\n\nX_tensor = torch.from_numpy(X_scaled).float()\ny_tensor = torch.from_numpy(y_class).float()\n\n# Convert one-hot vectors to integer class indices.\n# Using argmax to get the index of the hot value in each row.\ny_indices = y_tensor.long()\n\n# ------------------------------------------------------------------------------\n# 2. Create a Dataset and DataLoader\n# ------------------------------------------------------------------------------\ndataset = TensorDataset(X_tensor, y_indices)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# ------------------------------------------------------------------------------\n# 3. Define the network architecture\n# ------------------------------------------------------------------------------\nclass SimpleNet(nn.Module):\n    def __init__(self, input_size=25, hidden1=256, hidden2=512, hidden3=256, hidden4=128, num_classes=1203):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden1)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(hidden1, hidden2)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(hidden2, hidden3)\n        self.relu3 = nn.ReLU()\n        self.fc4 = nn.Linear(hidden3, hidden4)\n        self.relu4 = nn.ReLU()\n        self.fc5 = nn.Linear(hidden4, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu1(x)\n        x = self.fc2(x)\n        x = self.relu2(x)\n        x = self.fc3(x)\n        x = self.relu3(x)\n        x = self.fc4(x)\n        x = self.relu4(x)\n        x = self.fc5(x)  # No activation here; CrossEntropyLoss expects raw logits.\n        return x\n\n# ------------------------------------------------------------------------------\n# 4. Set device, instantiate model, loss function, and optimizer\n# ------------------------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = SimpleNet(input_size=25, num_classes=1203).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------------------\n# 5. Training loop\n# ------------------------------------------------------------------------------\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for batch_X, batch_y in dataloader:\n        # Move data to GPU\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        \n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_loss = running_loss / len(dataloader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n\n# ------------------------------------------------------------------------------\n# 6. After training, evaluate or save your model as needed\n# ------------------------------------------------------------------------------\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:06:18.193043Z","iopub.execute_input":"2025-02-11T12:06:18.193670Z","iopub.status.idle":"2025-02-11T12:06:49.484744Z","shell.execute_reply.started":"2025-02-11T12:06:18.193637Z","shell.execute_reply":"2025-02-11T12:06:49.484038Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch [1/100], Loss: 6.7484\nEpoch [2/100], Loss: 6.3492\nEpoch [3/100], Loss: 6.1261\nEpoch [4/100], Loss: 5.8587\nEpoch [5/100], Loss: 5.5850\nEpoch [6/100], Loss: 5.3379\nEpoch [7/100], Loss: 5.0787\nEpoch [8/100], Loss: 4.8249\nEpoch [9/100], Loss: 4.5567\nEpoch [10/100], Loss: 4.2756\nEpoch [11/100], Loss: 3.9880\nEpoch [12/100], Loss: 3.6943\nEpoch [13/100], Loss: 3.3850\nEpoch [14/100], Loss: 3.1012\nEpoch [15/100], Loss: 2.8091\nEpoch [16/100], Loss: 2.5310\nEpoch [17/100], Loss: 2.2750\nEpoch [18/100], Loss: 2.0652\nEpoch [19/100], Loss: 1.8371\nEpoch [20/100], Loss: 1.6772\nEpoch [21/100], Loss: 1.5027\nEpoch [22/100], Loss: 1.3731\nEpoch [23/100], Loss: 1.2357\nEpoch [24/100], Loss: 1.0856\nEpoch [25/100], Loss: 1.0298\nEpoch [26/100], Loss: 0.9209\nEpoch [27/100], Loss: 0.8414\nEpoch [28/100], Loss: 0.7567\nEpoch [29/100], Loss: 0.7114\nEpoch [30/100], Loss: 0.6223\nEpoch [31/100], Loss: 0.5508\nEpoch [32/100], Loss: 0.5781\nEpoch [33/100], Loss: 0.5418\nEpoch [34/100], Loss: 0.5130\nEpoch [35/100], Loss: 0.4684\nEpoch [36/100], Loss: 0.4289\nEpoch [37/100], Loss: 0.4830\nEpoch [38/100], Loss: 0.5327\nEpoch [39/100], Loss: 0.4544\nEpoch [40/100], Loss: 0.3960\nEpoch [41/100], Loss: 0.3981\nEpoch [42/100], Loss: 0.2986\nEpoch [43/100], Loss: 0.2628\nEpoch [44/100], Loss: 0.2495\nEpoch [45/100], Loss: 0.2595\nEpoch [46/100], Loss: 0.3017\nEpoch [47/100], Loss: 0.2800\nEpoch [48/100], Loss: 0.3184\nEpoch [49/100], Loss: 0.4873\nEpoch [50/100], Loss: 0.4862\nEpoch [51/100], Loss: 0.3590\nEpoch [52/100], Loss: 0.3137\nEpoch [53/100], Loss: 0.2404\nEpoch [54/100], Loss: 0.2341\nEpoch [55/100], Loss: 0.2208\nEpoch [56/100], Loss: 0.2140\nEpoch [57/100], Loss: 0.2970\nEpoch [58/100], Loss: 0.4133\nEpoch [59/100], Loss: 0.3641\nEpoch [60/100], Loss: 0.3665\nEpoch [61/100], Loss: 0.3043\nEpoch [62/100], Loss: 0.2088\nEpoch [63/100], Loss: 0.1570\nEpoch [64/100], Loss: 0.1453\nEpoch [65/100], Loss: 0.1358\nEpoch [66/100], Loss: 0.1377\nEpoch [67/100], Loss: 0.1346\nEpoch [68/100], Loss: 0.1337\nEpoch [69/100], Loss: 0.1361\nEpoch [70/100], Loss: 0.1360\nEpoch [71/100], Loss: 0.1327\nEpoch [72/100], Loss: 0.1339\nEpoch [73/100], Loss: 0.3393\nEpoch [74/100], Loss: 1.2705\nEpoch [75/100], Loss: 0.6162\nEpoch [76/100], Loss: 0.3084\nEpoch [77/100], Loss: 0.1793\nEpoch [78/100], Loss: 0.1442\nEpoch [79/100], Loss: 0.1428\nEpoch [80/100], Loss: 0.1365\nEpoch [81/100], Loss: 0.1419\nEpoch [82/100], Loss: 0.1352\nEpoch [83/100], Loss: 0.1340\nEpoch [84/100], Loss: 0.1526\nEpoch [85/100], Loss: 0.1715\nEpoch [86/100], Loss: 0.3311\nEpoch [87/100], Loss: 0.7526\nEpoch [88/100], Loss: 0.4205\nEpoch [89/100], Loss: 0.2560\nEpoch [90/100], Loss: 0.2098\nEpoch [91/100], Loss: 0.1716\nEpoch [92/100], Loss: 0.1386\nEpoch [93/100], Loss: 0.1421\nEpoch [94/100], Loss: 0.1470\nEpoch [95/100], Loss: 0.1435\nEpoch [96/100], Loss: 0.1311\nEpoch [97/100], Loss: 0.1274\nEpoch [98/100], Loss: 0.1249\nEpoch [99/100], Loss: 0.1253\nEpoch [100/100], Loss: 0.1240\nTraining complete.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"out = model(X_tensor.to(device))\nout","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:07:30.415896Z","iopub.execute_input":"2025-02-11T12:07:30.416200Z","iopub.status.idle":"2025-02-11T12:07:30.646551Z","shell.execute_reply.started":"2025-02-11T12:07:30.416174Z","shell.execute_reply":"2025-02-11T12:07:30.645591Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"tensor([[ -21.8709,  -29.4241,  -93.9286,  ...,  -67.2043, -139.1649,\n          -43.2219],\n        [ -34.8809,  -23.2436,  -38.5266,  ...,  -82.3025, -132.7822,\n          -62.6748],\n        [ -82.4847,  -85.5327, -207.6623,  ..., -168.4208, -201.7286,\n         -130.0891],\n        ...,\n        [ -77.7735,  -90.9384,  -92.8530,  ..., -116.1417,  -83.4920,\n          -78.0361],\n        [ -42.7854,  -26.1113,  -99.6544,  ..., -117.2792, -129.2907,\n          -48.9131],\n        [ -54.1021,  -62.6847, -116.9167,  ..., -189.4181, -190.3208,\n         -131.3539]], device='cuda:0', grad_fn=<AddmmBackward0>)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"nn_pred = out.argmax(dim=1).long()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:07:36.814250Z","iopub.execute_input":"2025-02-11T12:07:36.814581Z","iopub.status.idle":"2025-02-11T12:07:36.835352Z","shell.execute_reply.started":"2025-02-11T12:07:36.814550Z","shell.execute_reply":"2025-02-11T12:07:36.834759Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"nn_pred = nn_pred.to('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:08:13.280650Z","iopub.execute_input":"2025-02-11T12:08:13.280932Z","iopub.status.idle":"2025-02-11T12:08:13.284610Z","shell.execute_reply.started":"2025-02-11T12:08:13.280912Z","shell.execute_reply":"2025-02-11T12:08:13.283825Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_class, nn_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:08:14.639409Z","iopub.execute_input":"2025-02-11T12:08:14.639745Z","iopub.status.idle":"2025-02-11T12:08:14.645604Z","shell.execute_reply.started":"2025-02-11T12:08:14.639709Z","shell.execute_reply":"2025-02-11T12:08:14.644908Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.97\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model_path = \"simple_net_state_dict.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(f\"Model state dict saved to {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T12:09:14.539462Z","iopub.execute_input":"2025-02-11T12:09:14.539826Z","iopub.status.idle":"2025-02-11T12:09:14.550351Z","shell.execute_reply.started":"2025-02-11T12:09:14.539798Z","shell.execute_reply":"2025-02-11T12:09:14.549651Z"}},"outputs":[{"name":"stdout","text":"Model state dict saved to simple_net_state_dict.pth\n","output_type":"stream"}],"execution_count":25}]}